{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5165a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "\n",
    "\n",
    "request=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "wikipedia=BeautifulSoup(request.content)\n",
    "\n",
    "header_tags=[]\n",
    "\n",
    "for i in wikipedia.find_all(['h1','h2','h3','h4','h5','h6']):\n",
    "    header_tags.append(i.text)\n",
    "    \n",
    "    \n",
    "tags=pd.DataFrame({'Header tags':header_tags})\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "\n",
    "request=requests.get(\"https://www.imdb.com/list/ls091520106/\")\n",
    "imdb=BeautifulSoup(request.content)\n",
    "\n",
    "name = imdb.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "\n",
    "movies_name = [] \n",
    "\n",
    "for i in name:\n",
    "\n",
    "    for j in i.find_all(\"a\"):\n",
    "\n",
    "        movies_name.append(j.text)\n",
    "        \n",
    "Year=[]\n",
    "for i in imdb.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    Year.append(i.text)\n",
    "    \n",
    "rating=[]\n",
    "for i in imdb.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.split())\n",
    "    \n",
    "IMDB_100=pd.DataFrame({'Movie Name':movies_name,'Year of Release':Year,'Rating':rating})\n",
    "IMDB_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12b8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3\n",
    "\n",
    "request=requests.get(\"https://www.imdb.com/list/ls056092300/?sort=user_rating,desc&st_dt=&mode=detail&page=1\")\n",
    "imdb=BeautifulSoup(request.content)\n",
    "\n",
    "name = imdb.find_all(\"h3\", class_=\"lister-item-header\")\n",
    "\n",
    "movies_name = [] \n",
    "\n",
    "for i in name:\n",
    "\n",
    "    for j in i.find_all(\"a\"):\n",
    "\n",
    "        movies_name.append(j.text)\n",
    "        \n",
    "Year=[]\n",
    "for i in imdb.find_all('span',class_=\"lister-item-year text-muted unbold\"):\n",
    "    Year.append(i.text)\n",
    "    \n",
    "rating=[]\n",
    "for i in imdb.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.split())\n",
    "    \n",
    "IMDB_India=pd.DataFrame({'Movie Name':movies_name,'Year of Release':Year,'Rating':rating})\n",
    "IMDB_India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3352af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "\n",
    "request=requests.get(\"https://meesho.com/bags-ladies/pl/p7vbp\")\n",
    "meesho=BeautifulSoup(request.content)\n",
    "\n",
    "Name=[]\n",
    "for i in meesho.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 bWSOET NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS NewProductCard__ProductTitle_Desktop-sc-j0e7tu-4 cQhePS\"):\n",
    "    Name.append(i.text)\n",
    "    \n",
    "Price=[]\n",
    "for i in meesho.find_all('h5',class_=\"Text__StyledText-sc-oo0kvp-0 hiHdyy\"):\n",
    "    Price.append(i.text)\n",
    "    \n",
    "Discount=[]\n",
    "for i in meesho.find_all('p',class_=\"Text__StyledText-sc-oo0kvp-0 fCJVtz NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm NewProductCard__DiscountTextParagraph-sc-j0e7tu-16 kmYsnm\"):\n",
    "    Discount.append(i.text)\n",
    "    \n",
    "Product=pd.DataFrame({'Product Name':Name,'Price':Price,'Discount':Discount})\n",
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc367eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5(a)\n",
    "\n",
    "request=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "odi=BeautifulSoup(request.content)\n",
    "\n",
    "Name=[]\n",
    "for i in odi.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "Name=Name[0:10]   \n",
    "\n",
    "Matches=[]\n",
    "match=odi.find('td',class_=\"rankings-block__banner--matches\")\n",
    "for i in odi.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    Matches.append(i.text)\n",
    "    \n",
    "Matches=Matches[0:18:2]\n",
    "\n",
    "Matches.insert(0,match.text)\n",
    "\n",
    "Points=[]\n",
    "point=odi.find('td',class_=\"rankings-block__banner--points\")\n",
    "for i in odi.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    Points.append(i.text)\n",
    "    \n",
    "Points=Points[1:19:2]\n",
    "\n",
    "Points.insert(0,point.text)\n",
    "\n",
    "Ratings=[]\n",
    "rat=odi.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "for i in odi.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "Ratings=Ratings[0:9]\n",
    "\n",
    "Ratings.insert(0,rat.text.split()[0])\n",
    "\n",
    "\n",
    "ODI_Team=pd.DataFrame({'Name':Name,'Matches':Matches,'Points':Points,'Ratings':Ratings})\n",
    "ODI_Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d4e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5(b)\n",
    "\n",
    "request=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "odibat=BeautifulSoup(request.content)\n",
    "\n",
    "Name=[]\n",
    "top=odibat.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "name = odibat.find_all('td',class_=\"table-body__cell rankings-table__name name\") \n",
    "\n",
    "for i in name:\n",
    "\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Name.append(j.text)\n",
    "Name=Name[0:9]\n",
    "Name.insert(0,top.text)\n",
    "\n",
    "Team=[]\n",
    "team=odibat.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in odibat.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Team.append(i.text)\n",
    "    \n",
    "Team=Team[0:9]\n",
    "Team.insert(0,team.text.split()[0])\n",
    "\n",
    "Rating=[]\n",
    "rating=odibat.find('div',class_=\"rankings-block__banner--rating\")\n",
    "for i in odibat.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Rating=Rating[0:9]\n",
    "Rating.insert(0,rating.text)\n",
    "\n",
    "\n",
    "ODI_Bat=pd.DataFrame({'Name':Name,'Team':Team,'Rating':Rating})\n",
    "ODI_Bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1c463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5(c)\n",
    "\n",
    "request=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "odibow=BeautifulSoup(request.content)\n",
    "\n",
    "Name=[]\n",
    "top=odibow.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "name = odibow.find_all('td',class_=\"table-body__cell rankings-table__name name\") \n",
    "\n",
    "for i in name:\n",
    "\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Name.append(j.text)\n",
    "Name=Name[0:9]\n",
    "Name.insert(0,top.text)\n",
    "\n",
    "Team=[]\n",
    "team=odibow.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in odibow.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Team.append(i.text)\n",
    "    \n",
    "Team=Team[0:9]\n",
    "Team.insert(0,team.text.split()[0])\n",
    "\n",
    "Rating=[]\n",
    "rating=odibow.find('div',class_=\"rankings-block__banner--rating\")\n",
    "for i in odibow.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating.append(i.text)\n",
    "    \n",
    "Rating=Rating[0:9]\n",
    "Rating.insert(0,rating.text)\n",
    "\n",
    "\n",
    "ODI_Bow=pd.DataFrame({'Name':Name,'Team':Team,'Rating':Rating})\n",
    "ODI_Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83dafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "\n",
    "#(a)\n",
    "request=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "odiw=BeautifulSoup(request.content)\n",
    "\n",
    "Name=[]\n",
    "for i in odiw.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    Name.append(i.text)\n",
    "\n",
    "Name=Name[0:10]   \n",
    "\n",
    "Matches=[]\n",
    "match=odiw.find('td',class_=\"rankings-block__banner--matches\")\n",
    "for i in odiw.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    Matches.append(i.text)\n",
    "    \n",
    "Matches=Matches[0:18:2]\n",
    "\n",
    "Matches.insert(0,match.text)\n",
    "\n",
    "Points=[]\n",
    "point=odiw.find('td',class_=\"rankings-block__banner--points\")\n",
    "for i in odiw.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    Points.append(i.text)\n",
    "    \n",
    "Points=Points[1:19:2]\n",
    "\n",
    "Points.insert(0,point.text)\n",
    "\n",
    "Ratings=[]\n",
    "rat=odiw.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "for i in odiw.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "Ratings=Ratings[0:9]\n",
    "\n",
    "Ratings.insert(0,rat.text.split()[0])\n",
    "\n",
    "#(b)\n",
    "request=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "odibatw=BeautifulSoup(request.content)\n",
    "\n",
    "Name_b=[]\n",
    "top=odibatw.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "name = odibatw.find_all('td',class_=\"table-body__cell rankings-table__name name\") \n",
    "\n",
    "for i in name:\n",
    "\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Name_b.append(j.text)\n",
    "Name_b=Name_b[0:9]\n",
    "Name_b.insert(0,top.text)\n",
    "\n",
    "Team_b=[]\n",
    "team=odibatw.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in odibatw.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Team_b.append(i.text)\n",
    "    \n",
    "Team_b=Team_b[0:9]\n",
    "Team_b.insert(0,team.text.split()[0])\n",
    "\n",
    "Rating_b=[]\n",
    "rating=odibatw.find('div',class_=\"rankings-block__banner--rating\")\n",
    "for i in odibatw.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating_b.append(i.text)\n",
    "    \n",
    "Rating_b=Rating[0:9]\n",
    "Rating_b.insert(0,rating.text)\n",
    "\n",
    "#(c)\n",
    "request=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "odiround=BeautifulSoup(request.content)\n",
    "\n",
    "Name_r=[]\n",
    "top=odiround.find('div',class_=\"rankings-block__banner--name-large\")\n",
    "name = odiround.find_all('td',class_=\"table-body__cell rankings-table__name name\") \n",
    "\n",
    "for i in name:\n",
    "\n",
    "    for j in i.find_all(\"a\"):\n",
    "        Name_r.append(j.text)\n",
    "Name_r=Name_r[0:9]\n",
    "Name_r.insert(0,top.text)\n",
    "\n",
    "Team_r=[]\n",
    "team=odiround.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "for i in odiround.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    Team_r.append(i.text)\n",
    "    \n",
    "Team_r=Team_r[0:9]\n",
    "Team_r.insert(0,team.text.split()[0])\n",
    "\n",
    "Rating_r=[]\n",
    "rating=odiround.find('div',class_=\"rankings-block__banner--rating\")\n",
    "for i in odiround.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    Rating_r.append(i.text)\n",
    "    \n",
    "Rating_r=Rating_r[0:9]\n",
    "Rating_r.insert(0,rating.text)\n",
    "\n",
    "\n",
    "ODI_Round=pd.DataFrame({'Name':Name_r,'Team':Team_r,'Rating':Rating_r})\n",
    "\n",
    "ODI_BatW=pd.DataFrame({'Name':Name_b,'Team':Team_b,'Rating':Rating_b})\n",
    "\n",
    "ODI_TeamW=pd.DataFrame({'Name':Name,'Matches':Matches,'Points':Points,'Ratings':Ratings})\n",
    "\n",
    "print(ODI_TeamW)\n",
    "print('-'*40)\n",
    "print(ODI_BatW)\n",
    "print('-'*40)\n",
    "print(ODI_Round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dca279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 7\n",
    "\n",
    "request=requests.get(\"https://coreyms.com/\")\n",
    "cor=BeautifulSoup(request.content)\n",
    "\n",
    "title=[]\n",
    "tt=cor.find_all('h2',class_=\"entry-title\")\n",
    "for i in tt:\n",
    "    for j in i.find_all('a'):\n",
    "        title.append(j.text)\n",
    "        \n",
    "date=[]\n",
    "for i in cor.find_all('time',class_=\"entry-time\"):\n",
    "    date.append(i.text)\n",
    "    \n",
    "content=[]\n",
    "for i in cor.find_all('div',class_=\"entry-content\"):\n",
    "    content.append(i.text.split('\\n')[1])\n",
    "    \n",
    "code=[]\n",
    "for i in cor.find_all('iframe',class_=\"youtube-player\"):\n",
    "    code.append(i.get('src'))\n",
    "code.insert(4,'NaN')\n",
    "    \n",
    "CoreyMS=pd.DataFrame({'Heading':title,'Date':date,'Content':content,'YouTube Code':code})\n",
    "CoreyMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a7f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 8\n",
    "\n",
    "request=requests.get(\"https://www.nobroker.in/property/sale/bangalore/multiple?searchParam=W3sibGF0IjoxMi45NzgzNjkyLCJsb24iOjc3LjY0MDgzNTYsInBsYWNlSWQiOiJDaElKa1FOM0dLUVdyanNSTmhCUUpyaEdEN1UiLCJwbGFjZU5hbWUiOiJJbmRpcmFuYWdhciJ9LHsibGF0IjoxMi45OTgxNzMyLCJsb24iOjc3LjU1MzA0NDU5OTk5OTk5LCJwbGFjZUlkIjoiQ2hJSnhmVzREUE05cmpzUktzTlRHLTVwX1FRIiwicGxhY2VOYW1lIjoiUmFqYWppbmFnYXIifSx7ImxhdCI6MTIuOTMwNzczNSwibG9uIjo3Ny41ODM4MzAyLCJwbGFjZUlkIjoiQ2hJSjJkZGxaNWdWcmpzUmgxQk9BYWYtb3JzIiwicGxhY2VOYW1lIjoiSmF5YW5hZ2FyIn1d&radius=2.0&city=bangalore&locality=Indiranagar,&locality=Rajajinagar,&locality=Jayanagar\")\n",
    "house=BeautifulSoup(request.content)\n",
    "\n",
    "title=[]\n",
    "for i in house.find_all('h2',class_=\"heading-6 flex items-center font-semi-bold m-0\"):\n",
    "    title.append(i.text)\n",
    "    \n",
    "location=[]\n",
    "for i in house.find_all('div',class_=\"mt-0.5p overflow-hidden overflow-ellipsis whitespace-nowrap max-w-70 text-gray-light leading-4 po:mb-0 po:max-w-95\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "area=[]\n",
    "for i in house.find_all('h2',class_=\"heading-6 flex items-center font-semi-bold m-0\"):\n",
    "    area.append(i.text.split()[-2:])\n",
    "\n",
    "emi=[]\n",
    "for i in house.find_all('div',class_=\"font-semi-bold heading-6\"):\n",
    "    emi.append(i.text)\n",
    "emi=emi[1:15:3]\n",
    "\n",
    "price=[]\n",
    "for i in house.find_all('div',class_=\"font-semi-bold heading-6\"):\n",
    "    price.append(i.text)\n",
    "price=price[2:15:3]\n",
    "\n",
    "House_list=pd.DataFrame({'House Title':title,'Location':location,'Area':area,'EMI':emi,'Price':price})\n",
    "House_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b308ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 9\n",
    "\n",
    "request=requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "dine=BeautifulSoup(request.content)\n",
    "\n",
    "rest_name=[]\n",
    "for i in dine.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "    rest_name.append(i.text)\n",
    "        \n",
    "cu=dine.find_all('span',class_=\"double-line-ellipsis\")\n",
    "cuisine=[]\n",
    "for i in cu:\n",
    "    cuisine.append(i.text.split(\"|\")[1])\n",
    "\n",
    "location=[]\n",
    "for i in dine.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "    \n",
    "ratings=[]\n",
    "for i in dine.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "image_url=[]\n",
    "for i in dine.find_all('img',class_=\"no-img\"):\n",
    "    image_url.append(i.get('data-src'))\n",
    "\n",
    "    \n",
    "rest=pd.DataFrame({'Name':rest_name,'Cuisine':cuisine,'Location':location,'Rating':ratings,'Image URL':image_url})\n",
    "rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552861d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 10\n",
    "\n",
    "request=requests.get(\"https://www.bewakoof.com/women-tshirts?ga_q=tshirts\")\n",
    "shirt=BeautifulSoup(request.content)\n",
    "\n",
    "Name=[]\n",
    "for i in shirt.find_all('h3'):\n",
    "    Name.append(i.text)\n",
    "Name=Name[0:10]\n",
    "\n",
    "price=[]\n",
    "for i in shirt.find_all('span',class_=\"discountedPriceText\"):\n",
    "    price.append(i.text)\n",
    "    \n",
    "image=[]\n",
    "for i in shirt.find_all('img',class_=\"productImgTag\"):\n",
    "    image.append(i.get('src'))\n",
    "    \n",
    "Shirt=pd.DataFrame({'Product Name':Name,'Price':price,'Image URL':image})\n",
    "Shirt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9f1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
